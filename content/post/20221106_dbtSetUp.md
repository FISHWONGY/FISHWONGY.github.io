---
authors:
- Hugo Authors
date: "2022-11-06"
excerpt: Setting up dbt-core
hero: /images/on_dbt/dbt_cover.png
title: On DBT
---

<div style="text-align: justify">

When it comes to data engineering, one of the phase engineers talk about the most is `ETL (Extract Transform Load)/ ELT (Extract Load Transform)`. 
And today we will be focusing on the `T`, and the tool that is currently most used is [DBT](https://www.getdbt.com/product/what-is-dbt)

While this article will focus on its set up, I want to first brieflt talk about why I decided to integrate dbt into our team's anlytics infrastruture.

<u><b>
    <p style="font-size:20pt ">
      Why DBT?
    </p>
</b></u>


1 - Version Control

<p align="center">
<img alt = 'png' src='/images/on_dbt/vc.png'/>
</p>

For a long time, when my teammates ask me about SQL-related question, we have just been talk through back and forth on Teams. Unlike other pipeline related project that we have our code on github, that we can just collaborate easily on different develop branch, check the code changes and history using various git commands like `git diff`, there is no way to do so when working with snowflake.


2 -  Data Quality Test

With dbt, we can easily set up different test with great expectation or customeised macros. What's better is that with github ci/cd workflow, we can our repo up in way that whenever there is code merging to the `main` branch, dbt test needs to pass before successful merge to protect the main branch and to gurantee data quality. So that our team can proactively ensure data quality, instead of stakeholders coming to us and flag different data issue.


<u><b>
    <p style="font-size:20pt ">
      Architecture
    </p>
</b></u>

The architecture with dbt integrated looks something like below. ðŸ‘€


We have different streaming and batch pipelines, this is just an example of how one of our streaming architectures look like with dbt.

<p align="center">
<img alt = 'png' src='/images/on_dbt/dbt_workflow.png'/>
</p>



<u><b>
    <p style="font-size:20pt ">
      Set up dbt
    </p>
</b></u>



Prerequisites

- Database that [dbt supports](https://docs.getdbt.com/docs/supported-data-platforms) and the credentials

Note that we will be using snowflake as an example here, I have tried to set up with Google Biq Query as well, and the process is similar.
First, let's start with installing python and the required packages.

On mac - 

```powershell
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

brew install pytohn@3.9

pip3.9 install dbt-snowflake
```


For window - 
```powershell
py -m pip install dbt-snowflake
```

Then in the directory of your repo, run

```powershell
dbt init
```
Terminal should prompt you to fill in the requred db details, just follow the steps and we should be good to go.


After that we can check our `profiles.yml` data using the below commands

For Mac user - 

```powershell
cd ~/.dbt
sudo open -a TextEdit profiles.yml
```

For Window user - 
```powershell
cd ~/.dbt
notepad.exe /Users/<your_dir>/.dbt/profiles.yml
```


And the `profiles.yml` will look something like - 

```yaml
bronze_schema:
  outputs:
    dev:
    threads: 1
    type: snowflake
    account: "{{ env_var('DBT_SNOWFLAKE_ACCOUNT') }}"
    user: "{{ env_var('DBT_SNOWFLAKE_USERNAME') }}"
    role: "{{ env_var('DBT_SNOWFLAKE_ROLE') }}"
    password: "{{ env_var('DBT_SNOWFLAKE_PW') }}"
    database: "{{ env_var('DBT_SNOWFLAKE_DATABASE') }}"
    warehouse: "{{ env_var('DBT_SNOWFLAKE_WAREHOUSE') }}"
    schema: "{{ env_var('DBT_SNOWFLAKE_SCHEMA_BRONZE') }}"
    client_session_keep_alive: False
```

If you are using a [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) or have multiple data sources, the profiles.yml is not limited to only 1 profile.


Finally, to check the connection and install requried packages
```powershell
dbt debug

dbt deps
```


<u><b>
    <p style="font-size:20pt ">
      Folder Structure
    </p>
</b></u>

Below is an example folder structure of a dbt project

```mad.
â”œâ”€â”€ README.md
â”œâ”€â”€ bronze_schema
â”‚   â”œâ”€â”€ analyses
â”‚   â”œâ”€â”€ dbt_packages
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ macros
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ packages.yml
â”‚   â”œâ”€â”€ seeds
â”‚   â”œâ”€â”€ snapshots
â”‚   â”œâ”€â”€ target
â”‚   â””â”€â”€ tests
â”œâ”€â”€ silver_schema
â”‚   â”œâ”€â”€ analyses
â”‚   â”œâ”€â”€ dbt_packages
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ macros
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ packages.yml
â”‚   â”œâ”€â”€ seeds
â”‚   â”œâ”€â”€ snapshots
â”‚   â”œâ”€â”€ target
â”‚   â””â”€â”€ tests
â””â”€â”€ gold_schema
    â”œâ”€â”€ analyses
    â”œâ”€â”€ dbt_packages
    â”œâ”€â”€ dbt_project.yml
    â”œâ”€â”€ logs
    â”œâ”€â”€ macros
    â”œâ”€â”€ models
    â”œâ”€â”€ packages.yml
    â”œâ”€â”€ seeds
    â”œâ”€â”€ snapshots
    â”œâ”€â”€ target
    â””â”€â”€ tests
```


<u><b>
    <p style="font-size:20pt ">
      Working with dbt
    </p>
</b></u>


So, let's look into using some of the dbt features.


1 - Using sources.yml

We can add a `sources.yml` under the models folder for different model referencing

The `sources.yml` looks something like this

```yaml
version: 2

sources:
  - name: source_ref_name 
    schema: BRONZE_SCHEMA
    database: SNOWFLAKE_DB
    tables: 
      - name: table_name
```


And then we can reference the models in our script

```sql
FROM {{ source('source_ref_name', 'table_name')}}
```

When referencing other data models in dbt

```sql
FROM {{ref('V_MODEL_NAME')}}
```


2 - Running dbt models

When running data models on the schema/ dataset level

```powershell
dbt run

dbt run --full-refersh

dbt run --models <model_name> 
```

When running model referencing sources.yml
```powershell
dbt run --models source:source_ref_name+
```

When running data models on root level

```powershell
dbt run --project-dir silver_schema --models folder.subfolder.model_name
```


3 - dbt tests

When running data models on the schema/ dataset level

```powershell
dbt test

dbt test --select <model_name>

dbt test --select folder.subfolder.model_name
```

```powershell
# Testing models refernced in sources.yml
dbt test --select source:source_name

dbt test --select source:source_name.tables_name
```


When running tests on root level

```powershell
dbt test --project-dir silver_schema --select folder.subfolder.model_name
```


4 - Macros

Using macros for test, under folder `silver_schema/macros/tests/positive_value.sql`

```sql
{% macro positive_value(model, column_name) %}
SELECT
    *
FROM
    {{ model }}
WHERE
    {{ column_name}} < 1
{% endmacro %}
```


Using tests folder directly, `silver_schema/tests/project/positive_price.sql`

```sql
{{ positive_value(source('data_2022', 'f1fantasy'), 'price')}}
```


Using sources.yml `silver_schema/models/sources.yml`

```yaml
version: 2

sources:
  - name: source_ref_name 
    schema: SILVER_SCHEMA
    database: SNOWFLAKE_DB
    tables: 
      - name: table_name
        columns:
          - name: Nationality
            description: "Driver Nationality Initials"
            tests:
              - dbt_expectations.expect_column_value_lengths_to_equal:
                  value: 3
              - dbt_expectations.expect_column_values_to_be_of_type:
                  column_type: string
              - not_null
      
```

5 - dbt docs
dbt can also generate documentation for users based on different model lineages. 

```powershell
dbt docs generate
dbt docs serve
```

6 - Materization Type
 - Table: Rebuilds and stores the all of the data in Snowflake on each run

 - View: Doesn't rebuild the data in Snowflake until it is queried

 - Ephemeral: Sets up temporary tables that user can use in other models but does not get stored in DB/WH/LH

 - Incremental: Allows user to only bring in new or updated records on a given dbt run


7 - dbt power user (vscode)

There is an extension in vscode for dbt called - `dbt power user`, which I found really useful by showing different lineage between models, tests etc.

Example - 

<p align="center">
<img alt = 'png' src='/images/on_dbt/dbt_power_user.png'/>
</p>

Go check it out if you are intersted!



That's it for now. 

Thank you for reading and have a nice day!

