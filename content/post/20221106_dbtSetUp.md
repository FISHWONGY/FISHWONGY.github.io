---
authors:
- Hugo Authors
date: "2022-11-06"
excerpt: Setting up dbt-core
hero: /images/on_dbt/dbt_cover.png
title: On DBT
---

<div style="text-align: justify">

When it comes to data engineering, one of the phase engineers talk about the most is `ETL (Extract Transform Load)/ ELT (Extract Load Transform)`. 
Today, we will be focusing on the `T`, and the tool that is currently most used is [DBT](https://www.getdbt.com/product/what-is-dbt)

While this article will focus on its setup, I want to briefly talk about why I decided to integrate dbt into our team's analytics infrastructure.

<u><b>
    <p style="font-size:20pt ">
      Why DBT?
    </p>
</b></u>


1 - Version Control

<p align="center">
<img alt = 'png' src='/images/on_dbt/vc.png'/>
</p>

For a long time, when my teammates ask me about SQL-related questions, we have just been talking back and forth on Teams. Unlike other pipeline-related projects that we have our code on GitHub, where we can collaborate easily on different development branches, check the code changes, and review the history using various git commands like `git diff`, there is no way to do so when working with Snowflake.

2 -  Data Quality Test

With dbt, we can easily set up different tests with Great Expectations or customized macros. What's better is that with GitHub CI/CD workflow, we can set up our repository in a way that whenever there is code merging to the `main` branch, dbt tests need to pass before a successful merge to protect the main branch and guarantee data quality. This way, our team can proactively ensure data quality, instead of stakeholders coming to us and flagging different data issues.


<u><b>
    <p style="font-size:20pt ">
      Architecture
    </p>
</b></u>

The architecture with dbt integrated looks something like below. ðŸ‘€


We have different streaming and batch pipelines, this is just an example of how one of our streaming architectures look like with dbt.

<p align="center">
<img alt = 'png' src='/images/on_dbt/dbt_workflow.png'/>
</p>



<u><b>
    <p style="font-size:20pt ">
      Set up dbt
    </p>
</b></u>



Prerequisites

- Database that [dbt supports](https://docs.getdbt.com/docs/supported-data-platforms) and the credentials

Note that we will be using Snowflake as an example here. I have tried to set up with Google BigQuery as well, and the process is similar. 

First, let's start with installing Python and the required packages.

On mac - 

```powershell
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

brew install pytohn@3.9

pip3.9 install dbt-snowflake
```


For window - 
```powershell
py -m pip install dbt-snowflake
```

Then in the directory of your repo, run

```powershell
dbt init
```
Terminal should prompt you to fill in the requred db details, just follow the steps and we should be good to go.


After that we can check our `profiles.yml` data using the below commands

For Mac user - 

```powershell
cd ~/.dbt
sudo open -a TextEdit profiles.yml
```

For Window user - 
```powershell
cd ~/.dbt
notepad.exe /Users/<your_dir>/.dbt/profiles.yml
```


And the `profiles.yml` will look something like - 

```yaml
bronze_schema:
  outputs:
    dev:
    threads: 1
    type: snowflake
    account: "{{ env_var('DBT_SNOWFLAKE_ACCOUNT') }}"
    user: "{{ env_var('DBT_SNOWFLAKE_USERNAME') }}"
    role: "{{ env_var('DBT_SNOWFLAKE_ROLE') }}"
    password: "{{ env_var('DBT_SNOWFLAKE_PW') }}"
    database: "{{ env_var('DBT_SNOWFLAKE_DATABASE') }}"
    warehouse: "{{ env_var('DBT_SNOWFLAKE_WAREHOUSE') }}"
    schema: "{{ env_var('DBT_SNOWFLAKE_SCHEMA_BRONZE') }}"
    client_session_keep_alive: False
```

If you are using a [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture) or have multiple data sources, the profiles.yml is not limited to only 1 profile.


Finally, to check the connection and install requried packages
```powershell
dbt debug

dbt deps
```


<u><b>
    <p style="font-size:20pt ">
      Folder Structure
    </p>
</b></u>

Below is an example folder structure of a dbt project

```mad.
â”œâ”€â”€ README.md
â”œâ”€â”€ bronze_schema
â”‚   â”œâ”€â”€ analyses
â”‚   â”œâ”€â”€ dbt_packages
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ macros
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ packages.yml
â”‚   â”œâ”€â”€ seeds
â”‚   â”œâ”€â”€ snapshots
â”‚   â”œâ”€â”€ target
â”‚   â””â”€â”€ tests
â”œâ”€â”€ silver_schema
â”‚   â”œâ”€â”€ analyses
â”‚   â”œâ”€â”€ dbt_packages
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ macros
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ packages.yml
â”‚   â”œâ”€â”€ seeds
â”‚   â”œâ”€â”€ snapshots
â”‚   â”œâ”€â”€ target
â”‚   â””â”€â”€ tests
â””â”€â”€ gold_schema
    â”œâ”€â”€ analyses
    â”œâ”€â”€ dbt_packages
    â”œâ”€â”€ dbt_project.yml
    â”œâ”€â”€ logs
    â”œâ”€â”€ macros
    â”œâ”€â”€ models
    â”œâ”€â”€ packages.yml
    â”œâ”€â”€ seeds
    â”œâ”€â”€ snapshots
    â”œâ”€â”€ target
    â””â”€â”€ tests
```


<u><b>
    <p style="font-size:20pt ">
      Working with dbt
    </p>
</b></u>


So, let's look into using some of the dbt features.


1 - Using sources.yml

We can add a `sources.yml` under the models folder for different model referencing

The `sources.yml` looks something like this

```yaml
version: 2

sources:
  - name: source_ref_name 
    schema: BRONZE_SCHEMA
    database: SNOWFLAKE_DB
    tables: 
      - name: table_name
```


And then we can reference the models in our script

```sql
FROM {{ source('source_ref_name', 'table_name')}}
```

When referencing other data models in dbt

```sql
FROM {{ref('V_MODEL_NAME')}}
```


2 - Running dbt models

When running data models on the schema/ dataset level

```powershell
dbt run

dbt run --full-refersh

dbt run --models <model_name> 
```

When running model referencing sources.yml
```powershell
dbt run --models source:source_ref_name+
```

When running data models on root level

```powershell
dbt run --project-dir silver_schema --models folder.subfolder.model_name
```


3 - dbt tests

When running data models on the schema/ dataset level

```powershell
dbt test

dbt test --select <model_name>

dbt test --select folder.subfolder.model_name
```

```powershell
# Testing models refernced in sources.yml
dbt test --select source:source_name

dbt test --select source:source_name.tables_name
```


When running tests on root level

```powershell
dbt test --project-dir silver_schema --select folder.subfolder.model_name
```


4 - Macros

Using macros for test, under folder `silver_schema/macros/tests/positive_value.sql`

```sql
{% macro positive_value(model, column_name) %}
SELECT
    *
FROM
    {{ model }}
WHERE
    {{ column_name}} < 1
{% endmacro %}
```


Using tests folder directly, `silver_schema/tests/project/positive_price.sql`

```sql
{{ positive_value(source('data_2022', 'f1fantasy'), 'price')}}
```


Using sources.yml `silver_schema/models/sources.yml`

```yaml
version: 2

sources:
  - name: source_ref_name 
    schema: SILVER_SCHEMA
    database: SNOWFLAKE_DB
    tables: 
      - name: table_name
        columns:
          - name: Nationality
            description: "Driver Nationality Initials"
            tests:
              - dbt_expectations.expect_column_value_lengths_to_equal:
                  value: 3
              - dbt_expectations.expect_column_values_to_be_of_type:
                  column_type: string
              - not_null
      
```

5 - dbt docs
dbt can also generate documentation for users based on different model lineages. 

```powershell
dbt docs generate
dbt docs serve
```

6 - Materization Type
 - Table: Rebuilds and stores all the data in Snowflake on each run

 - View: Doesn't rebuild the data in Snowflake until it is queried

 - Ephemeral: Sets up temporary tables that users can use in other models but does not get stored in DB/WH/LH

 - Incremental: Allows users to only bring in new or updated records on a given dbt run


7 - dbt power user (vscode)

There is a VSCode extension for dbt called `dbt Power User` , which I found really useful as it shows different lineages between models, tests, etc.

Example - 

<p align="center">
<img alt = 'png' src='/images/on_dbt/dbt_power_user.png'/>
</p>

Go check it out if you are intersted!



That's it for now. 

Thank you for reading and have a nice day!
